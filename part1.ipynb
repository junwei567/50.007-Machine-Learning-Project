{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_train_data_file = \"./ES/train\"\n",
    "es_test_data_file = \"./ES/dev.in\"\n",
    "es_predicted_data_file = \"./ES/dev.p1.out\"\n",
    "es_actual_data_file = \"./ES/dev.out\"\n",
    "ru_train_data_file = \"./RU/train\"\n",
    "ru_test_data_file = \"./RU/dev.in\"\n",
    "ru_predicted_data_file = \"./RU/dev.p1.out\"\n",
    "ru_actual_data_file = \"./RU/dev.out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_training_file(file_path):\n",
    "    with open(file_path) as f_lines:\n",
    "        data = f_lines.read().splitlines()\n",
    "        data[:] = [x for x in data if x]\n",
    "\n",
    "    output = []\n",
    "    for i in data:\n",
    "        i = i.split(\" \")\n",
    "        if(len(i) > 2):\n",
    "            i = [\" \".join(i[0:len(i)-1]), i[len(i)-1]]\n",
    "            output.append(i)\n",
    "        else:\n",
    "            output.append(i)\n",
    "        \n",
    "    return output\n",
    "\n",
    "def _preprocess_testing_file(path):\n",
    "    with open(path) as f:\n",
    "        data = f.read().splitlines()\n",
    "\n",
    "    output = []\n",
    "    for word in data:\n",
    "        # if word: # leave the newlines or not?\n",
    "        output.append(word)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emission_using_MLE(training, k = 1):\n",
    "    tags = {}\n",
    "    tags_to_word = {}\n",
    "    emission = {}\n",
    "    for data in training:\n",
    "        word, tag = data[0], data[1]\n",
    "        if tag in tags:\n",
    "            tags[tag] += 1\n",
    "        else:\n",
    "            tags[tag] = 1\n",
    "        \n",
    "        tag_to_word = tuple((tag, word))\n",
    "        if tag_to_word in tags_to_word:\n",
    "            tags_to_word[tag_to_word] += 1\n",
    "        else:\n",
    "            tags_to_word[tag_to_word] = 1\n",
    "\n",
    "    for key in tags_to_word.keys():\n",
    "        emission[key] = tags_to_word[key] / (tags[key[0]] + k)\n",
    "    for key in tags.keys():\n",
    "        transition = tuple((key, \"#UNK#\"))\n",
    "        emission[transition] = k / (tags[key] + k)\n",
    "    # print(emission)\n",
    "    return emission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_probable_tag(emission):\n",
    "    highest_prob = {}\n",
    "    output = {}\n",
    "    for key, prob in emission.items():\n",
    "        tag, word = key[0], key[1]\n",
    "        if word not in highest_prob:\n",
    "            highest_prob[word] = prob\n",
    "            output[word] = tag\n",
    "        else:\n",
    "            if prob > highest_prob[word]:\n",
    "                highest_prob[word] = prob\n",
    "                output[word] = tag\n",
    "    # print(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_file(predicted_file, test_file, most_probable_tag):\n",
    "    f = open(predicted_file, \"w\")\n",
    "    for word in test_file:\n",
    "        if len(word) > 0:\n",
    "            try:\n",
    "                y = most_probable_tag[word]\n",
    "            except:\n",
    "                y = most_probable_tag[\"#UNK#\"]\n",
    "            f.write(f\"{word} {y}\\n\")\n",
    "        else: # leave the newlines??\n",
    "            f.write(\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ES_train_data = _preprocess_training_file(es_train_data_file)\n",
    "ES_test_data = _preprocess_testing_file(es_test_data_file)\n",
    "\n",
    "emission_parameters = get_emission_using_MLE(ES_train_data)\n",
    "most_probable_tag = get_most_probable_tag(emission_parameters)\n",
    "get_predicted_file(es_predicted_data_file, ES_test_data, most_probable_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6397645271553362"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_precision(path_predicted, path_actual):\n",
    "    correctly_predicted_entities = 0\n",
    "    predicted_entities = 0\n",
    "    with open(path_predicted) as f:\n",
    "        predicted_data = f.read().splitlines()\n",
    "        predicted_data[:] = [x for x in predicted_data if x]\n",
    "\n",
    "    with open(path_actual) as f:\n",
    "        actual_data = f.read().splitlines()\n",
    "        actual_data[:] = [x for x in actual_data if x]\n",
    "\n",
    "    for i in range(len(predicted_data)):\n",
    "        predicted_entities += 1\n",
    "        if predicted_data[i] == actual_data[i]:\n",
    "            correctly_predicted_entities += 1\n",
    "\n",
    "    return correctly_predicted_entities / predicted_entities\n",
    "\n",
    "evaluate_precision(es_predicted_data_file, es_actual_data_file)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6bea1edf50713343d797f2d3f5675b7d568eeccbe5314af310a951584ccf1264"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('data-sci': virtualenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
