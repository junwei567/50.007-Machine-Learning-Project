{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "519XeSJI5uss"
   },
   "outputs": [],
   "source": [
    "es_train_data_file = \"C:/Users/dksat/Documents/GitHub/50.007-Machine-Learning-Project/ES/train\"\n",
    "es_test_data_file = \"C:/Users/dksat/Documents/GitHub/50.007-Machine-Learning-Project/ES/dev.in\"\n",
    "es_predicted_data_file = \"C:/Users/dksat/Documents/GitHub/50.007-Machine-Learning-Project/ES/dev.out\"\n",
    "es_actual_data_file = \"C:/Users/dksat/Documents/GitHub/50.007-Machine-Learning-Project/ES/dev.out\"\n",
    "ru_train_data_file = \"C:/Users/dksat/Documents/GitHub/50.007-Machine-Learning-Project/RU/train\"\n",
    "ru_test_data_file = \"C:/Users/dksat/Documents/GitHub/50.007-Machine-Learning-Project/RU/dev.in\"\n",
    "ru_predicted_data_file = \"C:/Users/dksat/Documents/GitHub/50.007-Machine-Learning-Project/RU/dev.out\"\n",
    "ru_actual_data_file = \"C:/Users/dksat/Documents/GitHub/50.007-Machine-Learning-Project/RU/dev.out\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "SHXWcZ1y5syv"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def _preprocess_training_file(training_file):\n",
    "    tags = []\n",
    "    tags_with_start_stop = []\n",
    "    words = []    \n",
    "\n",
    "    with open(training_file,\"r\",encoding=\"utf8\") as f:\n",
    "        document = f.read().rstrip()\n",
    "        lines = document.split(\"\\n\\n\")\n",
    "\n",
    "        for line in lines:\n",
    "            words_ls = []\n",
    "            tags_ls = []\n",
    "            tags_with_start_stop = []\n",
    "            for word_tag in line.split(\"\\n\"):\n",
    "                word, tag = word_tag.split(\" \")\n",
    "                words_ls.append(word)\n",
    "                tags_ls.append(tag)\n",
    "\n",
    "            tag_ls_with_start_stop = [\"START\"] + tags_ls + [\"STOP\"]\n",
    "            tags.append(tags_ls)\n",
    "            tags_with_start_stop.append(tag_ls_with_start_stop)\n",
    "            words.append(words_ls)\n",
    "    return tags, tags_with_start_stop, words\n",
    "\n",
    "def _preprocess_test_file(testing_file):\n",
    "    test_words = []\n",
    "\n",
    "    with open(testing_file,\"r\",encoding=\"utf8\") as f:\n",
    "        document = f.read().rstrip()\n",
    "        lines = document.split(\"\\n\\n\")\n",
    "\n",
    "        for line in lines:\n",
    "            word_ls = []\n",
    "            for word in line.split(\"\\n\"):\n",
    "                word_ls.append(word)\n",
    "            test_words.append(word_ls)\n",
    "\n",
    "    return test_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_elements(lst):\n",
    "    return list(set(list(itertools.chain.from_iterable(lst))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "iQG7YbqyFDcZ"
   },
   "outputs": [],
   "source": [
    "def get_unique_tags(tags):\n",
    "    tags_unique = get_unique_elements(tags)\n",
    "    tags_unique.sort()\n",
    "    tags_unique_with_start_stop = [\"START\"] + tags_unique + [\"STOP\"]\n",
    "\n",
    "    return tags_unique, tags_unique_with_start_stop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "s0WjLO2p62UN"
   },
   "outputs": [],
   "source": [
    "def get_transition_pairs(tags):\n",
    "    transition_pairs = []\n",
    "\n",
    "    for tag in tags:\n",
    "        #yi-1 and yi tuples\n",
    "        for tag1, tag2 in zip(tags[:-1], tags[1:]):\n",
    "            transition_pairs.append([tag1, tag2])\n",
    "\n",
    "    return transition_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "XuW9JAL1hgFW"
   },
   "outputs": [],
   "source": [
    "def count_y(tag, tags):\n",
    "    tags_flattened = list(itertools.chain.from_iterable(tags))\n",
    "    return tags_flattened.count(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "3EHZmBMbFmGs"
   },
   "outputs": [],
   "source": [
    "def get_transition_using_MLE(tags_unique_with_start_stop, transition_pairs,\n",
    "                          tags_with_start_stop):\n",
    "  \n",
    "    transition = {}\n",
    "    #create matrix dimensions\n",
    "    for tag1 in tags_unique_with_start_stop[:-1]:\n",
    "        transition_row = {}\n",
    "        for tag2 in tags_unique_with_start_stop[1:]:\n",
    "            transition_row[tag2] = 0.0\n",
    "        transition[tag1] = transition_row\n",
    "\n",
    "    # populate transition parameters with counts\n",
    "    for tag1, tag2 in transition_pairs:\n",
    "        transition[tag1][tag2] += 1\n",
    "\n",
    "    # divide transition_count by count_yi, to get probability\n",
    "    for tag1, transition_row in transition.items():\n",
    "        count_yi = count_y(tag1, tags_with_start_stop)\n",
    "\n",
    "        # words in training set\n",
    "        for tag2, transition_count in transition_row.items():\n",
    "            if count_yi == 0:\n",
    "                transition[tag1][tag2] = 0.0\n",
    "            else:\n",
    "                transition[tag1][tag2] = transition_count / count_yi\n",
    "\n",
    "    return transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags, tags_with_start_stop, words = _preprocess_training_file(es_train_data_file)\n",
    "test_words = _preprocess_test_file(es_test_data_file)\n",
    "tags_unique_with_start_stop, tags_unique_with_start_stop = get_unique_tags(\n",
    "        tags)\n",
    "transition_pairs = get_transition_pairs(tags_with_start_stop)\n",
    "transition_matrix = get_transition_using_MLE(tags_unique_with_start_stop,\n",
    "                                              transition_pairs,\n",
    "                                              tags_with_start_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
